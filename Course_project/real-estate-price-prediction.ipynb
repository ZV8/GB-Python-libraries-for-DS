{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom catboost import CatBoostClassifier, CatBoostRegressor, Pool, cv, sum_models\nfrom sklearn import metrics\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import StandardScaler\nimport random\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/realestatepriceprediction/train.csv')\ntest = pd.read_csv('/kaggle/input/realestatepriceprediction/test.csv')\ntest['Price'] = ''\ncombine = [train, test]\ncombine = pd.concat(combine, ignore_index=True)\n\n# перенесем столбец с таргетом на первое место\ncols = combine.columns.tolist()\ncols = cols[-1:] + cols[:-1]\ncombine = combine[cols]\n\ncombine","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine['Square'][:10000].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('Square / train')\n\nplt.subplot(122)\nsns.kdeplot(combine['Square'][:10000], shade=True, legend=False)\nplt.xlabel('Square / train')\n\nplt.suptitle('Distribution of Square / train')\nplt.show()\n\n#\n\nplt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine['Square'][10000:].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('Square / test')\n\nplt.subplot(122)\nsns.kdeplot(combine['Square'][10000:], shade=True, legend=False)\nplt.xlabel('Square / test')\n\nplt.suptitle('Distribution of Square / test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #scatter plot totalbsmtsf/saleprice\nvar = 'Square'\ndata = pd.concat([combine[:10000].loc[combine['Rooms'] < 200]['Price'], combine[:10000].loc[combine['Rooms'] < 200][var]], axis=1)\ndata.plot.scatter(x=var, y='Price', ylim=(0,800000));","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменяем пустые значения средними\ncombine['LifeSquare'].fillna(value=combine['LifeSquare'].mean(), inplace=True)\ncombine['Healthcare_1'].fillna(value=combine['Healthcare_1'].mean(), inplace=True)\n\ncombine.isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменяем Rooms == 0 на 1\ncombine.at[combine.query('Rooms == 0').index, 'Rooms'] = 1\n\n# Заменяем Rooms > 6 на 2\ncombine.at[combine.query('Rooms > 6').index, 'Rooms'] = 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][:10000].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('KitchenSquare / train')\n\nplt.subplot(122)\nsns.kdeplot(combine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][:10000], shade=True, legend=False)\nplt.xlabel('KitchenSquare / train')\n\nplt.suptitle('KitchenSquare of Square / train')\nplt.show()\n\n#\n\nplt.figure(figsize = (16, 4))\n\nplt.subplot(121)\ncombine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][10000:].hist(density=True)\nplt.ylabel('count')\nplt.xlabel('KitchenSquare / test')\n\nplt.subplot(122)\nsns.kdeplot(combine.loc[combine['KitchenSquare'] < 25, 'KitchenSquare'][10000:], shade=True, legend=False)\nplt.xlabel('KitchenSquare / test')\n\nplt.suptitle('Distribution of KitchenSquare / test')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем дополнительные фичи\ncombine['squ_room'] = (combine['Square'] / combine['Rooms']).astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 'Price'\nnumfeat, catfeat = list(combine.select_dtypes(include=np.number))[1:], list(combine.select_dtypes(exclude=np.number))\ncatfeat.remove(target)\nprint(numfeat)\nprint(catfeat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем выбросы\n\nto_drop1 = combine[:10000].query('Square > 200').index\nto_drop2 = combine[:10000].query('LifeSquare > 200 & Rooms < 4').index\nto_drop3 = combine[:10000].query('KitchenSquare > 200').index\nto_drop4 = combine[:10000].query('HouseYear > 2020').index\nto_drop5 = combine[:10000].query('(Square < 13) | (Square < 20 & Rooms > 1)').index\n\ncombine.drop(list(to_drop1) + list(to_drop2) + list(to_drop3) + list(to_drop4) + list(to_drop5), axis=0, inplace=True)\n\nto_replace1 = combine[10000:].query('KitchenSquare > 200').index\ncombine.at[to_replace1, 'KitchenSquare'] = 24","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем дополнительные фичи\ncombine['squ_room'] = (combine['Square'] / combine['Rooms']).astype('float')\ncombine['squ_room']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_combine = len(combine)\nlen_test = 5000\nlen_validate = 3000\nlen_train = len_combine - (len_test+ len_validate)\nprint(len_combine)\nprint(len_test)\nprint(len_validate)\nprint(len_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим отдельно числовые слолбцы для категориальных\nfor n in numfeat:\n    combine[n + '_num'] = combine[n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine['Rooms'] = combine['Rooms'].astype('int')\ncombine['KitchenSquare'] = combine['KitchenSquare'].astype('int')\ncombine['HouseFloor'] = combine['HouseFloor'].astype('int')\ncombine['Square'] = combine['Square'].astype('int')\ncombine['Ecology_1'] = (combine['Ecology_1'] * 1000000).astype('int')\ncombine['LifeSquare'] = combine['LifeSquare'].astype('int')\ncombine[numfeat] = combine[numfeat].astype('str')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numfeat, catfeat = list(combine.select_dtypes(include=np.number))[1:], list(combine.select_dtypes(exclude=np.number))\ncatfeat.remove(target)\nprint(numfeat)\nprint(catfeat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = combine.corr()\n#Plot figsize\nfig, ax = plt.subplots(figsize=(10, 10))\n#Generate Heat Map, allow annotations and place floats in map\nsns.heatmap(corr, cmap='RdBu', annot=True, fmt=\".2f\")\n#Apply xticks\nplt.xticks(range(len(corr.columns)), corr.columns);\n#Apply yticks\nplt.yticks(range(len(corr.columns)), corr.columns)\n#show plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Удаляем из трейна неиспользуемые в тесте Square, HouseYear и DistrictId"},{"metadata":{"trusted":true},"cell_type":"code","source":"notest_Square = []\nfor x in combine.Square[:9972].sort_values().unique():\n    if len(combine[-5000:].loc[combine.Square == x]) > 0:\n        continue\n    else:\n        notest_Square.append(x)\nprint('Нет в тесте')\nprint(notest_Square) \n\nnotrain_Square = [] \nfor x in combine.Square[-5000:].sort_values().unique():\n    if len(combine[:9972].loc[combine.Square == x]) > 0:\n        continue\n    else:\n        notrain_Square.append(x)\nprint('Нет в трейне')\nprint(notrain_Square) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x14 = combine.loc[combine.Square_num < 14].index\ncombine.loc[x14, 'Square'] = combine[:10000]['Square'].mode()[0]\ncombine.loc[x14, 'LifeSquare'] = combine[:10000]['LifeSquare'].mode()[0]\ncombine.loc[x14, 'KitchenSquare'] = combine[:10000]['KitchenSquare'].mode()[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = combine.drop(combine.loc[combine.Square_num.isin(notest_Square)].index)\nlen(combine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notest_HouseYear = []\nfor x in combine.HouseYear[:9972].sort_values().unique():\n    if len(combine[-5000:].loc[combine.HouseYear == x]) > 0:\n        continue\n    else:\n        notest_HouseYear.append(x)\nprint('Нет в тесте')\nprint(notest_HouseYear) \n\nnotrain_HouseYear = [] \nfor x in combine.HouseYear[-5000:].sort_values().unique():\n    if len(combine[:9972].loc[combine.HouseYear == x]) > 0:\n        continue\n    else:\n        notrain_HouseYear.append(x)\nprint('Нет в трейне')\nprint(notrain_HouseYear) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = combine.drop(combine.loc[combine.HouseYear.isin(notest_HouseYear)].index)\nlen(combine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"notest_DistrictId = []\nfor x in combine.DistrictId[:9972].sort_values().unique():\n    if len(combine[-5000:].loc[combine.DistrictId == x]) > 0:\n        continue\n    else:\n        notest_DistrictId.append(x)\nprint('Нет в тесте')\nprint(notest_DistrictId) \n\nnotrain_DistrictId = [] \nfor x in combine.DistrictId[-5000:].sort_values().unique():\n    if len(combine[:9972].loc[combine.DistrictId == x]) > 0:\n        continue\n    else:\n        notrain_DistrictId.append(x)\nprint('Нет в трейне')\nprint(notrain_DistrictId) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combine = combine.drop(combine.loc[combine.DistrictId.isin(notest_DistrictId)].index)\n# combine = combine.drop(combine.loc[combine.DistrictId.isin(notrain_DistrictId)].index)\nlen(combine)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_combine = len(combine)\nlen_test = len(combine[combine.Price == ''])\nlen_validate = 3000\nlen_train = len_combine - (len_test+ len_validate)\nprint(len_combine)\nprint(len_test)\nprint(len_validate)\nprint(len_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"____\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_clusters_distribution(unique_labels, labels_counts):\n    \"\"\"Визуализация распределения классов по кластерам\"\"\"\n    plt.figure(figsize=(8,5))\n\n    plt.bar(unique, counts)\n\n    plt.xlabel('Clusters')\n    plt.xticks(unique)\n    plt.ylabel('Count')\n    plt.title('Clusters distribution')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\n\ncombine[numfeat] = scaler.fit_transform(combine[numfeat])\ncombine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_scaled = combine[:len_train + len_validate][numfeat]\nX_test_scaled = combine[len_train + len_validate:][numfeat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_3 = KMeans(n_clusters=3, random_state=42)\nlabels_clast_3 = kmeans_3.fit_predict(X_train_scaled)\nlabels_clast_3 = pd.Series(labels_clast_3, name='clusters_3')\nlabels_clast_3_test = kmeans_3.predict(X_test_scaled)\nlabels_clast_3_test = pd.Series(labels_clast_3_test, name='clusters_3')\n\nunique, counts = np.unique(labels_clast_3, return_counts=True)\ndisplay_clusters_distribution(unique, counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_5 = KMeans(n_clusters=5, random_state=42)\nlabels_clast_5 = kmeans_5.fit_predict(X_train_scaled)\nlabels_clast_5 = pd.Series(labels_clast_5, name='clusters_5')\nlabels_clast_5_test = kmeans_5.predict(X_test_scaled)\nlabels_clast_5_test = pd.Series(labels_clast_5_test, name='clusters_5')\n\nunique, counts = np.unique(labels_clast_5, return_counts=True)\ndisplay_clusters_distribution(unique, counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kmeans_10 = KMeans(n_clusters=10, random_state=42)\nlabels_clast_10 = kmeans_10.fit_predict(X_train_scaled)\nlabels_clast_10 = pd.Series(labels_clast_10, name='clusters_10')\nlabels_clast_10_test = kmeans_10.predict(X_test_scaled)\nlabels_clast_10_test = pd.Series(labels_clast_10_test, name='clusters_10')\n\nunique, counts = np.unique(labels_clast_10, return_counts=True)\ndisplay_clusters_distribution(unique, counts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clusters_3_dummies = pd.get_dummies(labels_clast_3, drop_first=False, prefix='clusters_3') #True\nclusters_5_dummies = pd.get_dummies(labels_clast_5, drop_first=False, prefix='clusters_5') #True\nclusters_10_dummies = pd.get_dummies(labels_clast_10, drop_first=False, prefix='clusters_10') #True\n\nclusters_3_dummies_test = pd.get_dummies(labels_clast_3_test, drop_first=False, prefix='clusters_3') #True\nclusters_5_dummies_test = pd.get_dummies(labels_clast_5_test, drop_first=False, prefix='clusters_5') #True\nclusters_10_dummies_test = pd.get_dummies(labels_clast_10_test, drop_first=False, prefix='clusters_10') #True\n\nclusters_3 = pd.concat([clusters_3_dummies, clusters_3_dummies_test], axis=0, ignore_index=True)\nclusters_5 = pd.concat([clusters_5_dummies, clusters_5_dummies_test], axis=0, ignore_index=True)\nclusters_10 = pd.concat([clusters_10_dummies, clusters_10_dummies_test], axis=0, ignore_index=True)\nclusters_all = pd.concat([clusters_5, clusters_10], axis=1)\n\ncombine[clusters_all.columns] = clusters_all.values\ncombine.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем столбцы с малозначащами фичами\ncombine = combine.drop(['Ecology_2', 'Shops_2'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"----"},{"metadata":{},"cell_type":"markdown","source":"### Обучаем модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"combine[:len_train + len_validate] = combine[:len_train + len_validate].sample(frac=1, random_state=5)\ncombine[:len_train + len_validate]\n\ntrain_data = combine[:len_train]\nvalidate_data = combine[len_train:len_train + len_validate]\ncv_data = combine[:len_train + len_validate]\ntest_data = combine[len_train + len_validate:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = train_data.iloc[:, 2:].values\nlabels = train_data.loc[:, 'Price'].values\nfeatures2 = validate_data.iloc[:, 2:].values\nlabels2 = validate_data.loc[:, 'Price'].values\nfeatures_test = test_data.iloc[:, 2:].values\nfeatures_cv = cv_data.iloc[:, 2:].values\nlabels_cv = cv_data.loc[:, 'Price'].values\nprint(features.shape, labels.shape, features2.shape, labels2.shape, features_test.shape, features_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = features\nX_validation = features2\ny_train = labels\ny_validation = labels2\nX_cv = features_cv\ny_cv = labels_cv\nprint(X_train.shape, X_validation.shape, y_train.shape, y_validation.shape, X_cv.shape)\n\n# from sklearn.model_selection import train_test_split\n# X_train, X_validation, y_train, y_validation = train_test_split(features_cv, labels_cv, train_size=0.5, random_state=100, shuffle=True)\n# print(X_train.shape, X_validation.shape, y_train.shape, y_validation.shape, X_cv.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_features = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n\n\ntrain_dataset = Pool(data=X_train,\n                     label=y_train,\n                     cat_features=cat_features)\n\neval_dataset = Pool(data=X_validation,\n                    label=y_validation,\n                    cat_features=cat_features)\n\n# pool_cv = Pool(data=X_cv, \n#                label=y_cv, \n#                cat_features=cat_features)\n\n# # Initialize CatBoostClassifier\n# # for classifier use Logloss, CrossEntropy, MultiClass, MultiClassOneVsAll or custom objective object\n# # for regressor use RMSE, MultiRMSE, MAE, Quantile, LogLinQuantile, Poisson, MAPE, Lq or custom objective object\nmodel = CatBoostRegressor(iterations=20000,\n                           #feature_weights = {\"35\":0.05},\n                           #thread_count=5,\n                           learning_rate = 0.03,\n                           depth=6, # только для grow_policy=\"Depthwise\"\n                           l2_leaf_reg=3,\n                           grow_policy=\"Depthwise\", # нессимитричное дерево (\"Depthwise\" как xgboost) (\"Lossguide\" как)\n                           #loss_function = 'Logloss', #MultiClass\n                           loss_function = 'RMSE', #RMSE\n                           eval_metric = 'R2', #R2\n                           early_stopping_rounds = 1000,\n                           task_type=\"GPU\", # закомментировать, если не на GPU\n                           devices='0', # закомментировать, если не на GPU\n                           #one_hot_max_size=10,\n                           verbose = False,\n                           use_best_model=True\n                         )\n\n# grid = {'learning_rate': [0.01, 0.03, 0.05],\n#         'depth': [5, 6],\n#         'l2_leaf_reg': [1, 3]}\n\n# model.grid_search(grid, X=pool_cv, verbose = False, plot=True, cv = 5)\n\n# Fit model\nmodel.fit(train_dataset, eval_set=eval_dataset, logging_level='Silent', plot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.best_iteration_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.get_feature_importance(eval_dataset, prettified=True)\n\nfeats = {}\nfor feature, importance in zip(combine.iloc[:, 2:].columns, model.feature_importances_):\n    feats[feature] = importance\nimportances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})\nimportances = importances.sort_values(by='Gini-Importance', ascending=False)\nimportances = importances.reset_index()\nimportances = importances.rename(columns={'index': 'Features'})\nsns.set(font_scale = 5)\nsns.set(style=\"whitegrid\", color_codes=True, font_scale = 1.7)\nfig, ax = plt.subplots()\nfig.set_size_inches(30,15)\nsns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')\nplt.xlabel('Importance', fontsize=25, weight = 'bold')\nplt.ylabel('Features', fontsize=25, weight = 'bold')\nplt.title('Feature Importance', fontsize=25, weight = 'bold')\ndisplay(plt.show())\ndisplay(importances)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_hat_train = [yhat for yhat in model.predict(X_train)]\nY_hat = [yhat for yhat in model.predict(X_validation)]\n\nfrom sklearn.metrics import r2_score\nprint(r2_score(y_train, Y_hat_train))\nprint(r2_score(y_validation, Y_hat))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Кросс валидация"},{"metadata":{"trusted":true},"cell_type":"code","source":"# cv\nparams = model.get_params()\n# del params['use_best_model']\npool_cv = Pool(data=X_cv, \n               label=y_cv, \n               cat_features=cat_features)\n\ncv_data = cv(\n   params = params,\n   pool = pool_cv,\n   fold_count=5,\n   inverted=False,\n   shuffle=True,\n   stratified=False,\n   partition_random_seed=0,\n    plot=\"True\"\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_data\nbest_value = np.max(cv_data['test-R2-mean'])\nbest_iter = np.argmax(cv_data['test-R2-mean'])\nprint('Best validation R2 score: {:.4f}±{:.4f} on step {}'.format(\n   best_value,\n   cv_data['test-R2-mean'][best_iter],\n   best_iter\n))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get predicted classes\npreds_class = model.predict(features_test)\npred = [value for value in preds_class]\n\nsubmission = pd.DataFrame({\n        \"Id\": test_data[\"Id\"],\n        \"Price\": pred\n    })\nsubmission.to_csv('prediction.csv', index=False)\nsubmission.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}